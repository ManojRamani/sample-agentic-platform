# Default values for langraph-chat.
# This is a YAML-formatted file.

# Specify the namespace where this service will be deployed
# Leave empty to use the namespace specified in the helm command
namespace: "default"

# Replica count for scaling
replicaCount: 1


# These values will be pulled from an overlay file. 
aws:
  region: ""
  account: ""

image:
  repository: "agentic-platform-llm-gateway"
  tag: latest
  pullPolicy: Always

nameOverride: "llm-gateway"
fullnameOverride: "llm-gateway"

service:
  type: ClusterIP
  port: 80
  targetPort: 8000

env:
  - name: PYTHONPATH
    value: /app

# Resource allocation
resources:
  requests:
    cpu: 100m      # 0.1 CPU core (10% of a core)
    memory: 256Mi  # 256 megabytes
  limits:
    memory: 512Mi  # 512 megabytes

# Ingress configuration
ingress:
  enabled: true
  path: "/llm-gateway"

# Service account for permissions
serviceAccount:
  name: "llm-gateway-sa"
  create: true
  irsaRoleName: "llm-gateway-role"  # This tells the template which secret key to use for IRSA


# Specify which keys this service needs from the central config
configKeys:
  - REDIS_HOST
  - REDIS_PORT
  - REDIS_PASSWORD_SECRET_ARN
  - DYNAMODB_USAGE_PLANS_TABLE
  - DYNAMODB_USAGE_LOGS_TABLE
  - COGNITO_USER_POOL_ID
  - COGNITO_USER_CLIENT_ID
  - COGNITO_M2M_CLIENT_ID
  - AWS_DEFAULT_REGION
  - ENVIRONMENT