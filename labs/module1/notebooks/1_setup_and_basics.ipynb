{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Amazon Bedrock\n",
    "\n",
    "Welcome! In this notebook, we'll set up our environment and learn the basics of working with Amazon Bedrock. Don't worry if you're new to this - we'll take it step by step.\n",
    "\n",
    "What you'll do in this lab:\n",
    "* Set up your environment. \n",
    "* Learn the basics of the converse API and LangGraph (more on that later)\n",
    "* Learn the basics of prompt engineering\n",
    "* Dive into retrieval augmented generation\n",
    "* Dive into function calling\n",
    "* Learn how to test this models (hint, it's different than unit/integ/system tests)\n",
    "\n",
    "\n",
    "After you complete this module, we'll start getting into the basics of agents!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import our dependencies and set up our Bedrock client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize the Bedrock client\n",
    "session = boto3.Session()\n",
    "bedrock = session.client(service_name='bedrock-runtime')\n",
    "\n",
    "print(\"✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you're having trouble with pip, try restarting the notebook. If all else fails pip install boto3 outside of the virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Converse() API\n",
    "Converse provides a consistent interface that works with all models that support messages. This allows you to write code once and use it with different models. If a model has unique inference parameters, you can also pass those unique parameters to the model.\n",
    "\n",
    "Amazon Bedrock doesn’t store any text, images, or documents that you provide as content. The data is only used to generate the response.\n",
    "\n",
    "You can submit a prompt by including it in the messages field, specifying the modelId of a foundation model or inference profile to run inference on it, and including any other fields that are relevant to your use case.\n",
    "\n",
    "### Your First Conversation\n",
    "\n",
    "Let's start with a simple conversation using Bedrocks [Converse API]('https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/converse.html') via the Python software development kit (SDK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "# Define the prompt text using XML tags for better Claude interaction\n",
    "PROMPT_TEXT: str = \"\"\"\n",
    "Please provide information about prompt engineering.\n",
    "\n",
    "<context>\n",
    "I am looking to learn about prompt engineering techniques and best practices.\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "Can you help me learn about prompt engineering? Be short and concise\n",
    "</question>\n",
    "\"\"\"\n",
    "\n",
    "# This is Bedrock converse() message format.\n",
    "initial_message: Dict[str, Any] = { \n",
    "    \"role\": \"user\", \n",
    "    \"content\": [{ \"text\": PROMPT_TEXT } ] \n",
    "}\n",
    "\n",
    "# Using a list, we can allow users to pass in more than just text. It supports other \"modalities\"\n",
    "# like images, videos, documents, and more!\n",
    "message_list: List[Dict[str, any]] = [initial_message]\n",
    "\n",
    "# The Model ID lets Bedrock know which model behind the unified API you'd like to select.\n",
    "# For this workshop we'll use Anthropic's Claude HAIKU 3.5. You can use a different model \n",
    "# if you choose. But make sure it's enabled under model access in the Bedrock console.\n",
    "MODEL_ID: str = \"us.anthropic.claude-3-5-haiku-20241022-v1:0\"\n",
    "\n",
    "# Send the message to Claude\n",
    "response: Dict[str, Any] = bedrock.converse(\n",
    "    modelId=MODEL_ID,\n",
    "    messages=message_list,\n",
    "    inferenceConfig={\n",
    "        \"maxTokens\": 2000,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the output\n",
    "Now that we have a response from the model let's investigate the output of Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the main response components\n",
    "print(\"\\n=== ASSISTANT'S RESPONSE (output.message) ===\")\n",
    "print(json.dumps(response['output']['message'], indent=4))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== TOKEN USAGE ===\")\n",
    "print(json.dumps(response['usage'], indent=4))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== PERFORMANCE METRICS ===\")\n",
    "print(json.dumps(response['metrics'], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Bedrock Converse API Response\n",
    "\n",
    "The response from Amazon Bedrock's Converse API provides a wealth of information beyond just the model's answer. Let's explore why this structured response format is particularly valuable:\n",
    "\n",
    "**1. Structured Response Format**\n",
    "\n",
    "The API returns the model's response in a consistent JSON format with the actual text content nested within the `output.message` structure. This standardized format makes it easy to:\n",
    "\n",
    "- Parse and extract specific elements programmatically\n",
    "- Handle multi-modal responses (text, images, etc.) with the same code\n",
    "- Maintain a consistent approach across different foundation models\n",
    "\n",
    "**2. Usage Metrics for Cost Management**\n",
    "\n",
    "The `usage` dictionary provides detailed token counts:\n",
    "\n",
    "- `inputTokens`: Number of tokens in your input\n",
    "- `outputTokens`: Number of tokens generated by the model\n",
    "- `totalTokens`: Combined token usage\n",
    "\n",
    "These metrics are essential for:\n",
    "- Tracking and allocating costs across projects or teams\n",
    "- Optimizing prompts to reduce token usage\n",
    "- Setting up budget alerts and constraints\n",
    "\n",
    "**Performance Metrics for Monitoring**\n",
    "\n",
    "The `metrics` dictionary gives you insights into model performance:\n",
    "\n",
    "- `latencyMs`: Total time taken for the API call\n",
    "\n",
    "These metrics help you:\n",
    "- Monitor system performance\n",
    "- Set appropriate timeouts in your applications\n",
    "- Compare different models for efficiency\n",
    "\n",
    "**Built-in CloudWatch Integration**\n",
    "\n",
    "One advantage of Amazon Bedrock is that these metrics are automatically published to Amazon CloudWatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this section, we've explored the basics of using Amazon Bedrock's Converse API to interact with foundation models like Claude. We've seen how to:\n",
    "\n",
    "- Structure requests using the standardized message format\n",
    "- Send prompts to the model using the Python SDK\n",
    "- Parse and extract different components of the response\n",
    "- Access usage statistics and performance metrics\n",
    "\n",
    "The Converse API provides a consistent interface across different foundation models, allowing you to switch models with minimal code changes. This flexibility, combined with the built-in observability through CloudWatch metrics, makes Amazon Bedrock a powerful platform for building AI-powered applications.\n",
    "\n",
    "As you progress through this workshop, you'll build on these fundamentals to create more complex interactions, implement retrieval augmented generation, explore function calling, and ultimately develop sophisticated AI agents. Each of these capabilities expands on the core interaction patterns we've established here.\n",
    "\n",
    "Let's move on to exploring prompt engineering techniques that will help you get the most out of these powerful foundation models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
