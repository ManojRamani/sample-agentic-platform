{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing LangGraph\n",
    "\n",
    "Now that we understand how to interact with foundation models using Amazon Bedrock's Converse API, we'll explore how to build more structured, multi-step AI applications using LangGraph.\n",
    "\n",
    "### What is LangGraph?\n",
    "\n",
    "LangGraph is a framework for creating stateful, multi-step workflows with large language models. While the Converse API handles basic back-and-forth interactions, LangGraph allows you to:\n",
    "\n",
    "- Build directed graphs of conversational states\n",
    "- Implement conditional logic and decision-making\n",
    "- Coordinate multiple AI and non-AI components\n",
    "\n",
    "### Why Use LangGraph?\n",
    "No reason other than it's helpful to get started. It's a tool in your toolbelt. There are other frameworks out there, but LangGraph is the most common to date. In later sections we'll discuss how to mix and match these frameworks using abstraction in your code.\n",
    "\n",
    "In the next notebook, we'll dive into building our first LangGraph application, where we'll explore these concepts hands-on. You'll see how these structured approaches can dramatically improve the reliability and capabilities of your AI applications.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import our dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "REGION = 'us-west-2'\n",
    "\n",
    "# Initialize the Bedrock client\n",
    "session = boto3.Session()\n",
    "bedrock = session.client(service_name='bedrock-runtime', region_name=REGION)\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Simple Conversation Graph\n",
    "\n",
    "Let's create a basic conversation flow that can:\n",
    "1. Take user input\n",
    "2. Process it with our LLM\n",
    "3. Return a response\n",
    "\n",
    "We'll build this step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, TypedDict\n",
    "from langgraph.graph import START, END, Graph\n",
    "\n",
    "# Define our state type - this maintains conversation context\n",
    "class State(TypedDict):\n",
    "    \"\"\"Type definition for our conversation state\"\"\"\n",
    "    messages: List[Dict[str, any]]  # History of all messages\n",
    "    current_message: str                # The latest user message\n",
    "\n",
    "# Create our LLM call function\n",
    "def call_llm(state: State) -> State:\n",
    "    \"\"\"Call Bedrock with the current conversation state\"\"\"\n",
    "    \n",
    "    # Configure inference parameters\n",
    "    inference_config: Dict[str, any] = {\n",
    "        \"maxTokens\": 2000,    # Maximum tokens to generate\n",
    "        \"temperature\": 0      # 0 = deterministic(ish), higher = more creative\n",
    "    }\n",
    "    \n",
    "    # Make the API call to Bedrock\n",
    "    response = bedrock.converse(\n",
    "        modelId=\"anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "        messages=state[\"messages\"],\n",
    "        inferenceConfig=inference_config\n",
    "    )\n",
    "    \n",
    "    # Add the response to our message history\n",
    "    state[\"messages\"].append(response['output']['message'])\n",
    "    return state\n",
    "\n",
    "# Create our graph\n",
    "workflow = Graph()\n",
    "\n",
    "# Add our LLM node to the graph\n",
    "workflow.add_node(\"llm\", call_llm)\n",
    "\n",
    "# Set up the flow: START -> LLM -> END\n",
    "workflow.add_edge(START, \"llm\")  # First, call the LLM\n",
    "workflow.add_edge(\"llm\", END)    # Then end the workflow\n",
    "\n",
    "# Compile the graph into an executable chain\n",
    "chain = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try out our conversation graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt text using XML tags for better Claude interaction\n",
    "PROMPT_TEXT = \"\"\"\n",
    "Explain what makes a good prompt.\n",
    "\n",
    "<context>\n",
    "I am seeking to understand the characteristics and elements that make an effective prompt for language models.\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "What makes a good prompt?\n",
    "</question>\n",
    "\"\"\"\n",
    "\n",
    "# Initial state\n",
    "initial_state = State(\n",
    "    messages=[{ \"role\": \"user\", \"content\": [ {\"text\": PROMPT_TEXT } ] } ],\n",
    "    current_message=\"\"\n",
    ")\n",
    "\n",
    "# Run our graph\n",
    "result: State = chain.invoke(initial_state)\n",
    "\n",
    "# Print the result\n",
    "print(json.dumps(result[\"messages\"][-1], indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've just created your first LangGraph conversation flow. This is a simple example, but in the next notebooks we'll build on this to create more complex and useful patterns constructed as graphs using LangGraph.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Try modifying the initial message to ask different questions about prompt engineering. What happens if you adjust the temperature parameter? Try values between 0 and 1 and observe how the responses change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
