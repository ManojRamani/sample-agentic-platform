{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”€ Question Classifier: The Routing Pattern\n",
    "\n",
    "Welcome to routing! This pattern shines when:\n",
    "- Different inputs need specialized handling\n",
    "- Classification can be done accurately\n",
    "- Optimizing for one type might hurt others\n",
    "\n",
    "Perfect for directing OpenSearch questions to the right experts! ðŸŽ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# No need to reinvent the wheel, lets pull this from our utilities folder\n",
    "from utils.retrieval_utils import get_chroma_os_docs_collection, ChromaDBRetrievalClient\n",
    "\n",
    "# Initialize the Bedrock client\n",
    "REGION = 'us-west-2'\n",
    "session = boto3.Session()\n",
    "bedrock = session.client(service_name='bedrock-runtime', region_name=REGION)\n",
    "\n",
    "# We've pushed the retrieval client from the prompt chaining notebook to the retrieval utils for simplicity\n",
    "chroma_os_docs_collection: ChromaDBRetrievalClient = get_chroma_os_docs_collection()\n",
    "\n",
    "print(\"âœ… Client setup and retrieval client complete!\")\n",
    "\n",
    "print(len(chroma_os_docs_collection.retrieve(query_text=\"How do I install OpenSearch on AWS?\", n_results=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Bedrock Helpers\n",
    "Next we'll reuse the helpers from the prompt chaining lab here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, Dict, Any, List\n",
    "\n",
    "# We pushed the base propmt from the previous lab to a a base prompt file.\n",
    "from utils.base_prompt import BasePrompt\n",
    "from utils.retrieval_utils import RetrievalResult\n",
    "\n",
    "def call_bedrock(prompt: BasePrompt) -> str:\n",
    "    kwargs = {\n",
    "        \"modelId\": prompt.model_id,\n",
    "        \"inferenceConfig\": prompt.hyperparams,\n",
    "        \"messages\": prompt.to_bedrock_messages(),\n",
    "        \"system\": prompt.to_bedrock_system(),\n",
    "    }\n",
    "\n",
    "    # Call Bedrock\n",
    "    converse_response: Dict[str, Any] = bedrock.converse(**kwargs)\n",
    "    # Get the model's text response\n",
    "    return converse_response['output']['message']['content'][0]['text']\n",
    "\n",
    "# Helper function to call bedrock\n",
    "def do_rag(user_input: str, rag_prompt: Type[BasePrompt]) -> str:\n",
    "    # Retrieve the context from the vector store\n",
    "    retrieval_results: List[RetrievalResult] = chroma_os_docs_collection.retrieve(user_input, n_results=2)\n",
    "    # Format the context into a string\n",
    "    context: str = \"\\n\\n\".join([result.document for result in retrieval_results])\n",
    "\n",
    "    print(\"Retrieval done\")\n",
    "    # Create the RAG prompt\n",
    "    inputs: Dict[str, Any] = {\"question\": user_input, \"context\": context}\n",
    "    rag_prompt: BasePrompt = rag_prompt(inputs=inputs)\n",
    "    # Call Bedrock with the RAG prompt\n",
    "\n",
    "    print(\"Calling Bedrock\")\n",
    "    return call_bedrock(rag_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating Our Question Router\n",
    "\n",
    "We'll build a classifier that routes questions to specialized handlers for:\n",
    "- Installation & Setup\n",
    "- Security & Authentication\n",
    "- Querying & Indexing\n",
    "- Performance Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets define our prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Dict, Any, List\n",
    "\n",
    "# Define the system prompt\n",
    "CLASSIFY_SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant specializing in OpenSearch documentation and support.\n",
    "\"\"\"\n",
    "\n",
    "RAG_SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant specializing in OpenSearch documentation and support.\n",
    "<instructions>\n",
    "1. Answer the question using only the documentation provided\n",
    "2. Be clear and concise with your answer. Your answers should be short, direct, and to the point\n",
    "3. Avoid saying \"based on the context provided\"\n",
    "4. If the answer isn't in the documentation, say \"I don't know\".\n",
    "</instructions>\n",
    "\"\"\"\n",
    "\n",
    "# Define reusable prompt templates as constants\n",
    "CLASSIFY_PROMPT_TEMPLATE = \"\"\"\n",
    "Classify this OpenSearch question into exactly one category:\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Categories:\n",
    "- INSTALL: Installation, setup, cluster configuration\n",
    "- SECURITY: Security, authentication, access control\n",
    "- QUERY: Querying, indexing, search operations\n",
    "- PERFORMANCE: Optimization, scaling, monitoring\n",
    "\n",
    "Respond with only the category code (e.g., 'INSTALL').\n",
    "\"\"\"\n",
    "\n",
    "INSTALLATION_PROMPT_TEMPLATE = \"\"\"\n",
    "Using the users qusetions below and provided context, provide detailed installation and setup guidance for OpenSearch:\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Include:\n",
    "- Step-by-step instructions\n",
    "- System requirements\n",
    "- Configuration options\n",
    "- Common issues and solutions\n",
    "\n",
    "Remember, your answers should be short, direct, and to the point. DO NOT include any preamble or introduction and DO NOT say \"based on the context provided\" or anything similar.\n",
    "\"\"\"\n",
    "\n",
    "SECURITY_PROMPT_TEMPLATE = \"\"\"\n",
    "Using the users qusetions below and provided context, provide security guidance for OpenSearch:\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Include:\n",
    "- Security best practices\n",
    "- Authentication setup\n",
    "- Access control configuration\n",
    "- Security implications\n",
    "\n",
    "Remember, your answers should be short, direct, and to the point. DO NOT include any preamble or introduction and DO NOT say \"based on the context provided\" or anything similar.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "QUERY_PROMPT_TEMPLATE = \"\"\"\n",
    "Using the users qusetions below and provided context, provide guidance on OpenSearch querying and indexing:\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Include:\n",
    "- Query examples\n",
    "- Index configuration\n",
    "- Best practices\n",
    "- Performance considerations\n",
    "\n",
    "Remember, your answers should be short, direct, and to the point. DO NOT include any preamble or introduction and DO NOT say \"based on the context provided\" or anything similar.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PERFORMANCE_PROMPT_TEMPLATE = \"\"\"\n",
    "Using the users qusetions below and provided context, provide performance optimization guidance for OpenSearch:\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Include:\n",
    "- Optimization strategies\n",
    "- Scaling considerations\n",
    "- Monitoring tips\n",
    "- Resource management\n",
    "\n",
    "Remember, your answers should be short, direct, and to the point. DO NOT include any preamble or introduction and DO NOT say \"based on the context provided\" or anything similar.\n",
    "\"\"\"\n",
    "\n",
    "# Define prompt classes that inherit from BasePrompt\n",
    "class ClassifyPrompt(BasePrompt):\n",
    "    system_prompt: str = CLASSIFY_SYSTEM_PROMPT\n",
    "    user_prompt: str = CLASSIFY_PROMPT_TEMPLATE\n",
    "\n",
    "class InstallationPrompt(BasePrompt):\n",
    "    system_prompt: str = RAG_SYSTEM_PROMPT\n",
    "    user_prompt: str = INSTALLATION_PROMPT_TEMPLATE\n",
    "\n",
    "class SecurityPrompt(BasePrompt):\n",
    "    system_prompt: str = RAG_SYSTEM_PROMPT\n",
    "    user_prompt: str = SECURITY_PROMPT_TEMPLATE\n",
    "\n",
    "class QueryPrompt(BasePrompt):\n",
    "    system_prompt: str = RAG_SYSTEM_PROMPT\n",
    "    user_prompt: str = QUERY_PROMPT_TEMPLATE\n",
    "\n",
    "class PerformancePrompt(BasePrompt):\n",
    "    system_prompt: str = RAG_SYSTEM_PROMPT\n",
    "    user_prompt: str = PERFORMANCE_PROMPT_TEMPLATE\n",
    "\n",
    "# Define the WorkflowState using TypedDict\n",
    "class WorkflowState(TypedDict):\n",
    "    question: str\n",
    "    category: str\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lets define our nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_question(state: WorkflowState) -> Dict[str, str]:\n",
    "    \"\"\"Classifies the question into a category\"\"\"\n",
    "    inputs = {\"question\": state['question']}\n",
    "    prompt = ClassifyPrompt(inputs=inputs)\n",
    "    \n",
    "    category = call_bedrock(prompt).strip()\n",
    "    state['category'] = category\n",
    "    return {\"category\": category}\n",
    "\n",
    "def handle_installation(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Handles installation & setup questions\"\"\"    \n",
    "    state['response'] = do_rag(state['question'], InstallationPrompt)\n",
    "    return state\n",
    "\n",
    "def handle_security(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Handles security & authentication questions\"\"\"\n",
    "    state['response'] = do_rag(state['question'], SecurityPrompt)\n",
    "    return state\n",
    "\n",
    "def handle_querying(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Handles querying & indexing questions\"\"\"\n",
    "    state['response'] = do_rag(state['question'], QueryPrompt)\n",
    "    return state\n",
    "\n",
    "def handle_performance(state: WorkflowState) -> WorkflowState:\n",
    "    \"\"\"Handles performance optimization questions\"\"\"\n",
    "    state['response'] = do_rag(state['question'], PerformancePrompt)\n",
    "    return state\n",
    "\n",
    "def init_state(question: str) -> WorkflowState:\n",
    "    \"\"\"Initialize the workflow state with a question.\"\"\"\n",
    "    return WorkflowState(\n",
    "        question=question,\n",
    "        category=\"\",\n",
    "        response=\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Because our nodes are individual functions that take in a state dictionary. we can test them individually. Lets test our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do I install OpenSearch on AWS?\"\n",
    "state: WorkflowState = init_state(question=question)\n",
    "classify_question(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How do I install OpenSearch on AWS?\"\n",
    "state: WorkflowState = init_state(question=question)\n",
    "handle_installation(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Routing Graph\n",
    "Next lets create and compile our graph. We can use a conditional check to route each question to the correct prompt that's tuned to provide the relevant information from each type of document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_routing_workflow() -> StateGraph:\n",
    "    \"\"\"Creates a workflow for routing OpenSearch questions\"\"\"\n",
    "    workflow = StateGraph(WorkflowState)\n",
    "    \n",
    "    # Add nodes to our graph\n",
    "    workflow.add_node(\"classify\", classify_question)\n",
    "    workflow.add_node(\"install\", handle_installation)\n",
    "    workflow.add_node(\"security\", handle_security)\n",
    "    workflow.add_node(\"query\", handle_querying)\n",
    "    workflow.add_node(\"performance\", handle_performance)\n",
    "    \n",
    "    # Create conditional routing\n",
    "    workflow.add_edge(START, \"classify\")\n",
    "    \n",
    "    # Create conditional edges based on the category\n",
    "    workflow.add_conditional_edges(\n",
    "        \"classify\",\n",
    "        lambda state: state[\"category\"],\n",
    "        {\n",
    "            \"INSTALL\": \"install\",\n",
    "            \"SECURITY\": \"security\",\n",
    "            \"QUERY\": \"query\",\n",
    "            \"PERFORMANCE\": \"performance\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # All handlers lead to END\n",
    "    workflow.add_edge(\"install\", END)\n",
    "    workflow.add_edge(\"security\", END)\n",
    "    workflow.add_edge(\"query\", END)\n",
    "    workflow.add_edge(\"performance\", END)\n",
    "    \n",
    "    # Compile and return the workflow\n",
    "    return workflow.compile()\n",
    "\n",
    "graph: StateGraph = create_routing_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing with Various Questions\n",
    "\n",
    "Let's test our router with different types of OpenSearch questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our workflow\n",
    "graph: StateGraph = create_routing_workflow()\n",
    "\n",
    "# Test questions covering different categories\n",
    "test_questions = [\n",
    "    \"How do I install OpenSearch on AWS?\",\n",
    "    \"What's the best way to implement role-based access control?\",\n",
    "    \"How can I write efficient fuzzy match queries?\",\n",
    "    \"What's the optimal shard size for large indices?\",\n",
    "    \"How do I configure SSL/TLS for cluster security?\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ”€ Testing our question router...\\n\")\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    state: WorkflowState = init_state(question=question)\n",
    "    result = graph.invoke(state)\n",
    "    print(f\"Category: {result['category']}\")\n",
    "    print(f\"Response: {result['response']}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Benefits of the Routing Pattern\n",
    "\n",
    "Our question routing system provides several advantages:\n",
    "\n",
    "âœ… Specialized handling for each category\n",
    "\n",
    "âœ… More focused and accurate responses\n",
    "\n",
    "âœ… Easy to add new categories\n",
    "\n",
    "âœ… Clear separation of concerns\n",
    "\n",
    "Next, we'll explore parallel processing to generate multiple solution approaches simultaneously! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
