{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 Building Autonomous Agents: Adding Tools\n",
    "\n",
    "Welcome to the next step in building autonomous agents! In this notebook, we'll focus on expanding an LLM's capabilities by giving it access to tools.\n",
    "\n",
    "Autonomous agents need to interact with their environment, and tools are the foundation that allows LLMs to take actions beyond just generating text. By providing tools to a language model, we enable it to perform specific tasks like searching for information, making calculations, or accessing external systems.\n",
    "\n",
    "## Objectives:\n",
    "- Understand the role of tools in autonomous agents\n",
    "- Create and register tools for LLM use\n",
    "- Implement a basic tool-using agentic system with LangGraph\n",
    "- Observe how tools transform a passive LLM into an active agent\n",
    "\n",
    "Throughout this notebook, we'll build a simple agent that can use tools to answer questions to extend the models capabilities. This forms the foundation for the more advanced agent architectures we'll explore in later notebooks.\n",
    "\n",
    "Let's begin by setting up our environment and defining our first set of tools! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies. \n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Initialize the Bedrock client\n",
    "session = boto3.Session()\n",
    "bedrock = session.client(service_name='bedrock-runtime')\n",
    "\n",
    "print(\"✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lab, we added memory to that chat bot. Let's extend this chat bot to use tools. In a similar fashion, we'll implement this with vanilla Python and then show you how it would look in LangGraph.\n",
    "\n",
    "We also made a case for owning our own types as abstraction layers for all things that touch LLMs. Creating abstractions is the best way to make 2-way door decisions if you decide you, for example want to use crew.ai or pydantic ai instead of LangGraph. The less you abstract away, the harder the refactor will be if you change your mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse what we wrote in the previous lab. \n",
    "We've pushed the types and converters from the previous lab into a common folder (similar to what exists in the agent platform). We'll just import them for reuse here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_platform.core.models.prompt_models import BasePrompt\n",
    "from agentic_platform.core.models.memory_models import Message, SessionContext, ToolResult, ToolCall\n",
    "from agentic_platform.core.models.llm_models import LLMResponse, LLMResponse\n",
    "\n",
    "from typing import Dict, Any, Optional, List, Type, Callable\n",
    "\n",
    "# Clients.\n",
    "class MemoryClient:\n",
    "    \"\"\"Manages conversations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.conversations: Dict[str, SessionContext] = {}\n",
    "\n",
    "    def upsert_conversation(self, conversation: SessionContext) -> bool:\n",
    "        self.conversations[conversation.session_id] = conversation\n",
    "\n",
    "    def get_or_create_conversation(self, conversation_id: str=None) -> SessionContext:\n",
    "        return self.conversations.get(conversation_id, SessionContext()) if conversation_id else SessionContext()\n",
    "    \n",
    "memory_client: MemoryClient = MemoryClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tool Specification\n",
    "For our tool calls we need a tool specification. Each API provider has a slightly different tool spec making the need for abstraction necessary. We'll define our own below. \n",
    "\n",
    "**Note**: With model context protocol or MCP (discussed in module 4), there's an initiative to standardize these specifications moving forward which would be a huge leap for the community. We'll base our tool spec off MCPs, but implement it in a way that pydantic models can be used to generate the tool specs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_platform.core.models.tool_models import ToolSpec\n",
    "\n",
    "ToolSpec??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuse Bedrock Call\n",
    "The call_bedrock function from the previous lab was almost complete. We need to modify the LLMRequest object to accept our new ToolSpecs. Lets do that now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import Converse API converter to convert the raw JSON into our own types.\n",
    "from agentic_platform.core.converter.llm_request_converters import ConverseRequestConverter\n",
    "from agentic_platform.core.converter.llm_response_converters import ConverseResponseConverter\n",
    "from agentic_platform.core.models.llm_models import LLMRequest, LLMResponse\n",
    "\n",
    "# Helper function to call Bedrock. Passing around JSON is messy and error prone.\n",
    "def call_bedrock(request: LLMRequest) -> LLMResponse:\n",
    "    kwargs: Dict[str, Any] = ConverseRequestConverter.convert_llm_request(request)\n",
    "    # Call Bedrock\n",
    "    converse_response: Dict[str, Any] = bedrock.converse(**kwargs)\n",
    "    # Get the model's text response\n",
    "    return ConverseResponseConverter.to_llm_response(converse_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test out our new types! We'll do two tests.\n",
    "1. We'll generate structured output (as a pydantic model) from our tool calling. \n",
    "2. We'll use the model to pick which tool to use\n",
    "\n",
    "To get structured output, we can use force_tool from the converse API to force the tool use. This will give us our structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "# Create a pydantic model we want to use for structured output.\n",
    "class WeatherReport(BaseModel):\n",
    "    temperature: float\n",
    "    condition: str\n",
    "\n",
    "# Then create a ToolSchema instance (not a class inheriting from it)\n",
    "weather_tool = ToolSpec(\n",
    "    model=WeatherReport,\n",
    "    name=\"weather_report\",\n",
    "    description=\"Useful for getting the weather report for a location.\"\n",
    ")\n",
    "\n",
    "# Create a list of tools we want to use. for this example we only have one.\n",
    "tools: List[ToolSpec] = [weather_tool]\n",
    "\n",
    "# Create a prompt with our system and user messages.\n",
    "prompt: BasePrompt = BasePrompt(\n",
    "    system_prompt=\"You are a weather reporter. You are given a location and you need to report the weather.\",\n",
    "    user_prompt=\"What is the weather in San Francisco?\",\n",
    ")\n",
    "\n",
    "request: LLMRequest = LLMRequest(\n",
    "    system_prompt = prompt.system_prompt,\n",
    "    messages = [ Message.from_text(role=\"user\", text=prompt.user_prompt) ],\n",
    "    model_id = prompt.model_id,\n",
    "    hyperparams = prompt.hyperparams,\n",
    "    tools = tools,\n",
    "    force_tool = \"weather_report\"\n",
    ")\n",
    "\n",
    "response: LLMResponse = call_bedrock(request)\n",
    "\n",
    "# We know that there's only one tool invocation.\n",
    "tool_invocation: ToolCall = response.tool_calls[0]\n",
    "\n",
    "# Using Pydantics, model_validate(), we can validate the tool invocation is in the correct format.\n",
    "my_weather_report: WeatherReport = WeatherReport.model_validate(tool_invocation.arguments)\n",
    "\n",
    "print(my_weather_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Using our types, we can easily pass in single tools, force the tool use and get back structured output as pydantic models! Passing around JSON is messy. This gives us a very clean way to work with LLMs without passing around raw text or arbitrary json blobs.\n",
    "\n",
    "Next, let's try a more complicated tool us pattern. Let's create two python functions we can wrap. \n",
    "\n",
    "As a first step let's create another tool and add it to our tool list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Operation(str, Enum):\n",
    "    add = \"add\"\n",
    "    subtract = \"subtract\"\n",
    "    multiply = \"multiply\"\n",
    "    divide = \"divide\"\n",
    "\n",
    "class Calculator(BaseModel):\n",
    "    operation: Operation\n",
    "    x: float\n",
    "    y: float\n",
    "\n",
    "# Create a tool spec for our calculator.\n",
    "calculator_tool: ToolSpec = ToolSpec(\n",
    "    model=Calculator,\n",
    "    name=\"calculate\",\n",
    "    description=\"Perform a mathematical calculation.\"\n",
    ")\n",
    "\n",
    "# Now we have two tools to choose from!\n",
    "tools: List[ToolSpec] = [weather_tool, calculator_tool]\n",
    "\n",
    "# Create a prompt with our system and user messages.\n",
    "class AgentPrompt(BasePrompt):\n",
    "    system_prompt: str = \"You are a helpful assistant. You are given tools to help you accomplish your task. You can choose to use them or not.\"\n",
    "    user_prompt: str = \"{user_message}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in our user message to the Base Prompt.\n",
    "inputs: Dict[str, Any] = {\"user_message\": \"What is 2 + 2?\"}\n",
    "prompt: AgentPrompt = AgentPrompt(inputs=inputs)\n",
    "\n",
    "request: LLMRequest = LLMRequest(\n",
    "    system_prompt = prompt.system_prompt,\n",
    "    messages = [ Message.from_text(role=\"user\", text=prompt.user_prompt) ],\n",
    "    model_id = prompt.model_id,\n",
    "    hyperparams = prompt.hyperparams,\n",
    "    tools = tools\n",
    ")\n",
    "\n",
    "# call bedrock\n",
    "response: LLMResponse = call_bedrock(request)\n",
    "\n",
    "# Get the tool incocation\n",
    "tool_invocations: List[ToolCall] = response.tool_calls\n",
    "\n",
    "print(tool_invocations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! The model is correctly picking the right tool and filling in the tool spec definition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a Pause\n",
    "In the code above, we created types for almost everything that touches Bedrock from our LLMResponse to our tool specifications or ToolSpecs. This is great progress! \n",
    "\n",
    "### What's next? \n",
    "* Update our Message object to handle tool calls\n",
    "* Tie the actual tool implementations to the ToolSpec objects and put the tools in our agent.\n",
    "\n",
    "First lets start by creating our tool implementations and adding them to the ToolSpecs we already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "# This function takes in the arguments defined as a pydantic model.\n",
    "def weather_report(weather_input: WeatherReport) -> str:\n",
    "    \"\"\"Weather report tool\"\"\"    \n",
    "    # NOTE: In a real implementation, we'd call an external API here.\n",
    "    return \"The weather is sunny and 70 degrees.\"\n",
    "\n",
    "def handle_calculation(args: Calculator) -> float:\n",
    "    \"\"\"Process the calculation request and return a result\"\"\"\n",
    "    x = args.x\n",
    "    y = args.y\n",
    "\n",
    "    operator: Operation = args.operation\n",
    "    \n",
    "    if operator == 'add':\n",
    "        result = x + y\n",
    "    elif operator == 'subtract':\n",
    "        result = x - y\n",
    "    elif operator == 'multiply':\n",
    "        result = x * y\n",
    "    elif operator == 'divide':\n",
    "        result = x / y if y != 0 else 'Error: Division by zero'\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the functions to the tool schemas. In practice you'd want to do this on the tool spec creation instead \n",
    "# of mutating the tool spec after creation. In subsequent labs, we'll learn how to use decorators to do this.\n",
    "weather_tool.function = weather_report\n",
    "calculator_tool.function = handle_calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Tool Use to our Agent\n",
    "Let's take our chat bot implementation that has memory and extend it to do tool use.\n",
    "\n",
    "We'll use the tool definition from the first notebook for performing math or making up weather reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# Import our agent request and response types.\n",
    "from agentic_platform.core.models.api_models import AgenticRequest, AgenticRequest, AgenticResponse\n",
    "from agentic_platform.core.models.memory_models import TextContent\n",
    "\n",
    "# Lets reuse this from the previous lab.\n",
    "memory_client: MemoryClient = MemoryClient()\n",
    "\n",
    "# Create a prompt with our system and user messages.\n",
    "class AgentPrompt(BasePrompt):\n",
    "    system_prompt: str = \"You are a helpful assistant. You are given tools to help you accomplish your task. You can choose to use them or not.\"\n",
    "    user_prompt: str = \"{user_message}\"\n",
    "\n",
    "\n",
    "class ToolCallingAgent:\n",
    "    # This is new, we're adding tools in the constructor to bind them to the agent.\n",
    "    # Don't get too attached to this idea, it'll change as we get into MCP.\n",
    "    def __init__(self, tools: List[ToolSpec], prompt: BasePrompt):\n",
    "        self.tools: List[ToolSpec] = tools\n",
    "        self.conversation: SessionContext = SessionContext()\n",
    "        self.prompt: BasePrompt = prompt\n",
    "\n",
    "    def call_llm(self) -> LLMResponse:\n",
    "        # Create LLM request\n",
    "        request: LLMRequest = LLMRequest(\n",
    "            system_prompt=self.prompt.system_prompt,\n",
    "            messages=self.conversation.get_messages(),\n",
    "            model_id=self.prompt.model_id,\n",
    "            hyperparams=self.prompt.hyperparams,\n",
    "            tools=self.tools\n",
    "        )\n",
    "\n",
    "        # Call the LLM.\n",
    "        response: LLMResponse = call_bedrock(request)\n",
    "        # Append the llms response to the conversation.\n",
    "        self.conversation.add_message(Message(\n",
    "            role=\"assistant\",\n",
    "            text=response.text,\n",
    "            tool_calls=response.tool_calls\n",
    "        ))\n",
    "        # Return the response.\n",
    "        return response\n",
    "    \n",
    "    def execute_tools(self, llm_response: LLMResponse) -> List[ToolResult]:\n",
    "        \"\"\"Call tools and return the results.\"\"\"\n",
    "        # It's possible that the model will call multiple tools.\n",
    "        tool_results: List[ToolResult] = []\n",
    "        # Iterate over the tool calls and call the tool.\n",
    "        for tool_invocation in llm_response.tool_calls:\n",
    "            # Get the tool spec for the tool call.\n",
    "            tool: ToolSpec = next((t for t in self.tools if t.name == tool_invocation.name), None)\n",
    "            # Call the tool.\n",
    "            input_data: BaseModel = tool.model.model_validate(tool_invocation.arguments)\n",
    "            function_result: str = str(tool.function(input_data))\n",
    "            tool_response: ToolResult = ToolResult(\n",
    "                id=tool_invocation.id,\n",
    "                content=[TextContent(text=function_result)],\n",
    "                isError=False\n",
    "            )\n",
    "\n",
    "            print(f\"Tool response: {tool_response}\")\n",
    "\n",
    "            # Add the tool result to the list.\n",
    "            tool_results.append(tool_response)\n",
    "\n",
    "        # Add the tool results to the conversation\n",
    "        message: Message = Message(role=\"user\", tool_results=tool_results)\n",
    "        self.conversation.add_message(message)\n",
    "        \n",
    "        # Return the tool results even though we don't use it.\n",
    "        return tool_results\n",
    "    \n",
    "    def invoke(self, request: AgenticRequest) -> AgenticResponse:\n",
    "        # Get or create conversation\n",
    "        self.conversation = memory_client.get_or_create_conversation(request.session_id)\n",
    "        # Add user message to conversation\n",
    "        self.conversation.add_message(request.message)\n",
    "\n",
    "        # Keep calling LLM until we get a final response\n",
    "        while True:\n",
    "            # Call the LLM\n",
    "            response: LLMResponse = self.call_llm()\n",
    "            \n",
    "            # If the model wants to use tools\n",
    "            if response.stop_reason == \"tool_use\":\n",
    "                # Execute the tools\n",
    "                self.execute_tools(response)\n",
    "                # Continue the loop to get final response\n",
    "                continue\n",
    "            \n",
    "            # If we get here, it's a final response \n",
    "            break\n",
    "\n",
    "        # Save updated conversation\n",
    "        memory_client.upsert_conversation(self.conversation)\n",
    "\n",
    "        # Return our own type.\n",
    "        return AgenticResponse(\n",
    "            message=self.conversation.messages[-1], # Just return the last message\n",
    "            session_id=self.conversation.session_id\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Agent\n",
    "Now that we have a tool calling agent, lets invoke it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to construct request\n",
    "def construct_request(user_message: str, conversation_id: str=None) -> AgenticRequest:\n",
    "    return AgenticRequest.from_text(\n",
    "        text=user_message, \n",
    "        **{'session_id': conversation_id}\n",
    "    )\n",
    "\n",
    "agent: ToolCallingAgent = ToolCallingAgent(\n",
    "    tools=[weather_tool, calculator_tool],\n",
    "    prompt=AgentPrompt()\n",
    ")\n",
    "\n",
    "# Invoke the agent\n",
    "user_message: str = \"What is the weather in SF?\"\n",
    "request: AgenticRequest = construct_request(user_message)\n",
    "response: AgenticResponse = agent.invoke(request)\n",
    "\n",
    "# Print the response\n",
    "print(response.message.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Because we're updating the conversation and outputting it to our memory client, we can use the conversation id to get the conversation. Conveniently, the conversation object kind of acts as a trace so we can view it to see what our agent did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the conversation in the memory client.\n",
    "convo: SessionContext = memory_client.get_or_create_conversation(response.session_id)\n",
    "\n",
    "for message in convo.messages:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success!\n",
    "We were able to build an agent that does tool calling in ~100 lines of code using the abstraction layers we put in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What did we just do?\n",
    "You just successfully built your first autonomous agent! In a modern way (as of 2025), you just built what is commonly referred as a ReACT agent. \n",
    "\n",
    "ReACT was the first major orchestration technique that gained traction. With ReACT an LLM is given a prompt describing tools it has access to and a scratch pad for dumping intermediate step results. ReACT is inspired by human abilities to “reason” and “act” to complete tasks. \n",
    "\n",
    "When ReACT first came out, function calling didn't exist yet. So the original prompt that looked like this:\n",
    "```\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "```\n",
    "\n",
    "This prompt was designed to make it easier to regex out API calls to do multi-turn conversations and actions. You can now pretty much do that out of the box with the converse API and a while loop (which is what we did). The thoughts and observation chain is now handled by the messages passed into the converse API and you really only need to make small tweaks do ReACT with the converse API directly. \n",
    "\n",
    "tl;dr: You pretty much already implemented ReACt in the previous workshop and built your first full fledged agent!\n",
    "\n",
    "\n",
    "\n",
    "# Next Steps\n",
    "With this approach, we can add more and more tools to our agent. For example, if you want the agent to do a search online, we could just define a new ToolSpec, add it to our agent and it would work as is!\n",
    "\n",
    "Next, we'll explore how to add retrieval to our agent 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-program-technical-assets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
