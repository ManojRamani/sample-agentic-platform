{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Building Autonomous Agents: Exploring Agent Frameworks:\n",
    "\n",
    "In this module, we'll examine how different agent frameworks implement autonomous agents, focusing specifically on LangChain/LangGraph, PydanticAI, and CrewAI. We'll explore how these frameworks handle orchestration, tool use, and agent coordination while leveraging our existing abstractions.\n",
    "\n",
    "Objectives:\n",
    "* Get hands on with high-level frameworks like LangChain/LangGraph, PydanticAI, and CrewAI\n",
    "* Learn how to integrate our tool calling, memory, and conversation abstractions with each framework\n",
    "* Implement examples showing how to maintain consistent interfaces across frameworks\n",
    "* Understand when to use each framework based on their strengths and application needs\n",
    "\n",
    "By the end of this module, you'll understand how to build on top of these frameworks while reusing your existing code, allowing you to choose the right framework for each use case without starting from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "We've already explored LangGraph a bit in module 2, but we haven't spent much time with LangChain. In this section, we'll be using the langchain-aws repo to play with LangChain on Bedrock. We'll try to accomplish 3 things\n",
    "* Discuss abstraction layers\n",
    "* Discuss pros/cons\n",
    "* Recreate the agent we built in the previous notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets start with a very simple chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! As an AI language model, I don't have feelings or emotions, but I'm operating properly and ready to assist you with any questions or tasks you may have. How can I help you today?\" additional_kwargs={} response_metadata={'ResponseMetadata': {'RequestId': '7b8d04ab-7117-4e35-a4a0-8469bea025d2', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 17 May 2025 20:43:43 GMT', 'content-type': 'application/json', 'content-length': '367', 'connection': 'keep-alive', 'x-amzn-requestid': '7b8d04ab-7117-4e35-a4a0-8469bea025d2'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1949]}, 'model_name': 'us.anthropic.claude-3-sonnet-20240229-v1:0'} id='run-793797b8-a2e4-403e-931b-152ff49ea7e3-0' usage_metadata={'input_tokens': 20, 'output_tokens': 45, 'total_tokens': 65}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Bedrock chat model\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_core.messages import AIMessage, BaseMessage\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"us.anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Invoke the llm\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"Hello! How are you today?\"),\n",
    "]\n",
    "\n",
    "response: AIMessage =llm.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting LangChain to work out of the box is very simple. Now lets recreate the agent we built in the previous lab with LangChain.\n",
    "\n",
    "First lets reuse our tools from the previous lab. We can leverage a nice abstraction LangGraph provides called create_react_agent() to take these tools and quickly create an agent. \n",
    "\n",
    "In essence, this abstracts away a lot of the work we did in the previous notebook to build a ReACT like agent! One cool thing about frameworks is that they usually take in \"callable's\" meaning you can just pass in a function with a doc string and it'll work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"What's the weather in San Francisco?\" additional_kwargs={} response_metadata={} id='56397164-5ca9-49ae-a1ed-fe9dc75157f3'\n",
      "content=[{'type': 'text', 'text': \"Okay, let's get the weather report for San Francisco:\"}, {'type': 'tool_use', 'name': 'weather_report', 'input': {'input': {'location': 'San Francisco'}}, 'id': 'tooluse_YPS85wspTuyLImIkw8DkvA'}] additional_kwargs={} response_metadata={'ResponseMetadata': {'RequestId': '2f0f5bca-d6a4-4b93-9cb3-a91d9e6bd241', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 17 May 2025 20:43:46 GMT', 'content-type': 'application/json', 'content-length': '367', 'connection': 'keep-alive', 'x-amzn-requestid': '2f0f5bca-d6a4-4b93-9cb3-a91d9e6bd241'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [3197]}, 'model_name': 'us.anthropic.claude-3-sonnet-20240229-v1:0'} id='run-892f84c6-cacf-416c-8066-906827260eaa-0' tool_calls=[{'name': 'weather_report', 'args': {'input': {'location': 'San Francisco'}}, 'id': 'tooluse_YPS85wspTuyLImIkw8DkvA', 'type': 'tool_call'}] usage_metadata={'input_tokens': 306, 'output_tokens': 73, 'total_tokens': 379}\n",
      "content='The weather is sunny and 70 degrees.' name='weather_report' id='4b3d9e35-a887-4947-aa27-0be11a8a85fe' tool_call_id='tooluse_YPS85wspTuyLImIkw8DkvA'\n",
      "content='The weather report shows it is currently sunny and 70 degrees Fahrenheit in San Francisco.' additional_kwargs={} response_metadata={'ResponseMetadata': {'RequestId': '3f8df123-e754-46f6-a726-f582e8686e12', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 17 May 2025 20:43:47 GMT', 'content-type': 'application/json', 'content-length': '273', 'connection': 'keep-alive', 'x-amzn-requestid': '3f8df123-e754-46f6-a726-f582e8686e12'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [656]}, 'model_name': 'us.anthropic.claude-3-sonnet-20240229-v1:0'} id='run-76d1eaa4-6d0d-42c2-a790-12aabfef62fd-0' usage_metadata={'input_tokens': 399, 'output_tokens': 24, 'total_tokens': 423}\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any, List, Callable\n",
    "\n",
    "# Import our tools from the previous lab.\n",
    "from agentic_platform.core.tool.sample_tools import weather_report, handle_calculation\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.graph import Graph\n",
    "\n",
    "# Use the prebuilt react agent from LangGraph\n",
    "agent: Graph = create_react_agent(model=llm, tools=[weather_report, handle_calculation])\n",
    "\n",
    "# Invoke the agent\n",
    "inputs = {\"messages\": [(\"user\", \"What's the weather in San Francisco?\")]}\n",
    "response = agent.invoke(inputs)\n",
    "# Print the response\n",
    "for message in response['messages']:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! In just a couple lines of code were able to recreate the work we did in a previous 3 labs!\n",
    "\n",
    "## A Word on Lock-in. \n",
    "Using LangGraph / LangChain (or any framework) makes sense in scenarios like this. It does exactly what we need it to do out of the box. However, it has it's own types (messages), it's own model invocation implementation, etc.. You can use them, but it creates a 1-way door decision. If you need to build something custom, use different framework, swap out a long term memory implementation, etc.. it will be very painful to undo the tight coupling of a framework.\n",
    "\n",
    "To solve this, we just need to wrap the code above into our own types and then the rest of the system doesn't care what framework you're using. It's a little extra work but provides a lot more flexibility. As things become more standard, this might become less of a problem. But for now, the best way to create 2-way doors is to use your own types. \n",
    "\n",
    "Now lets wrap the agent above in our own abstractions to create interoperability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is undifferentiated converter code so we pushed it to the common folder.\n",
    "# LangChains message format differs significantly from other model APIs so we had to take some short cuts.\n",
    "# Ex) Tool Calls are converted into strings even though it's a pydantic model. \n",
    "# LangChain also has the concept of a tool message which some providers use but others don't.\n",
    "# This is why we have a converter.\n",
    "from agentic_platform.core.converter.langchain_converters import LangChainMessageConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets build our agent and use our abstractions to create interoperability between our custom agent and LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentic_platform.core.models.api_models import AgentRequest, AgentResponse\n",
    "from agentic_platform.core.models.prompt_models import BasePrompt\n",
    "from agentic_platform.core.models.memory_models import Message, SessionContext\n",
    "from typing import Dict, Any, List, Callable\n",
    "\n",
    "# Lets reuse our memory client from the previous lab.\n",
    "# Clients.\n",
    "class MemoryClient:\n",
    "    \"\"\"Manages conversations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.conversations: Dict[str, SessionContext] = {}\n",
    "\n",
    "    def upsert_conversation(self, conversation: SessionContext) -> bool:\n",
    "        self.conversations[conversation.session_id] = conversation\n",
    "\n",
    "    def get_or_create_conversation(self, conversation_id: str=None) -> SessionContext:\n",
    "        return self.conversations.get(conversation_id, SessionContext()) if conversation_id else SessionContext()\n",
    "\n",
    "from langchain_core.tools import Tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.graph import Graph\n",
    "\n",
    "memory_client: MemoryClient = MemoryClient()\n",
    "\n",
    "class LangChainAgent:\n",
    "    \n",
    "    def __init__(self, tools: List[Callable], base_prompt: BasePrompt):\n",
    "        # Do some conversions to take our types and make them work with LangChain.\n",
    "        temp: float = base_prompt.hyperparams[\"temperature\"] if \"temperature\" in base_prompt.hyperparams else 0.5\n",
    "        llm: ChatBedrockConverse = ChatBedrockConverse(\n",
    "            model=base_prompt.model_id,\n",
    "            temperature=temp\n",
    "        )\n",
    "\n",
    "        # We'll use a prebuilt graph from langgraph that implements the same React pattern.\n",
    "        # This should be done at instantiation time to reduce the overhead of re-compiling the graph.\n",
    "        self.agent: Graph = create_react_agent(model=llm, tools=tools)\n",
    "        self.conversation: SessionContext = None\n",
    "\n",
    "    def invoke(self, request: AgentRequest) -> AgentResponse:\n",
    "        # Get or create conversation\n",
    "        self.conversation = memory_client.get_or_create_conversation(request.session_id)\n",
    "        # Add user message to conversation\n",
    "        self.conversation.add_message(Message(role=\"user\", text=request.text))\n",
    "        # Convert to langchain messages\n",
    "        inputs = {\"messages\": [(\"user\", request.text)]}\n",
    "        response = self.agent.invoke(inputs)\n",
    "        print(response['messages'])\n",
    "        # Convert to our response format\n",
    "        messages: List[Message] = LangChainMessageConverter.convert_langchain_messages(response['messages'])\n",
    "        # Add messages to conversation\n",
    "        self.conversation.add_messages(messages)\n",
    "        # Save the conversation\n",
    "        memory_client.upsert_conversation(self.conversation)\n",
    "        # Return the response\n",
    "        return AgentResponse(\n",
    "            session_id=self.conversation.session_id,\n",
    "            message=messages[-1].text\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='What is the weather in San Francisco?', additional_kwargs={}, response_metadata={}, id='c8afbb48-331e-4c46-94ed-180b42849ee5'), AIMessage(content=[{'type': 'text', 'text': \"I'll help you get the current weather report for San Francisco. I'll use the weather_report tool to retrieve this information.\"}, {'type': 'tool_use', 'name': 'weather_report', 'input': {'input': {'location': 'San Francisco'}}, 'id': 'tooluse_eq8U0srOTF6b5EVBKcoNDg'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'c751eb18-c986-4a19-b010-78d8ec7c5857', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 17 May 2025 20:43:49 GMT', 'content-type': 'application/json', 'content-length': '440', 'connection': 'keep-alive', 'x-amzn-requestid': 'c751eb18-c986-4a19-b010-78d8ec7c5857'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1611]}, 'model_name': 'us.anthropic.claude-3-5-haiku-20241022-v1:0'}, id='run-6a029673-6d92-439e-acb5-0ed3b8368209-0', tool_calls=[{'name': 'weather_report', 'args': {'input': {'location': 'San Francisco'}}, 'id': 'tooluse_eq8U0srOTF6b5EVBKcoNDg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 411, 'output_tokens': 86, 'total_tokens': 497}), ToolMessage(content='The weather is sunny and 70 degrees.', name='weather_report', id='50dae603-c67f-4024-8d82-66ab2eed80dd', tool_call_id='tooluse_eq8U0srOTF6b5EVBKcoNDg'), AIMessage(content=\"Based on the weather report, it's a beautiful day in San Francisco! The weather is sunny with a temperature of 70 degrees. It sounds like a perfect day to enjoy outdoor activities or explore the city.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '98bcada9-0fe1-4f61-a7c3-d9ec35e23672', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sat, 17 May 2025 20:43:51 GMT', 'content-type': 'application/json', 'content-length': '384', 'connection': 'keep-alive', 'x-amzn-requestid': '98bcada9-0fe1-4f61-a7c3-d9ec35e23672'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1594]}, 'model_name': 'us.anthropic.claude-3-5-haiku-20241022-v1:0'}, id='run-def1d75f-9abd-4920-96b8-da63495a354e-0', usage_metadata={'input_tokens': 517, 'output_tokens': 47, 'total_tokens': 564})]\n",
      "Based on the weather report, it's a beautiful day in San Francisco! The weather is sunny with a temperature of 70 degrees. It sounds like a perfect day to enjoy outdoor activities or explore the city.\n"
     ]
    }
   ],
   "source": [
    "from agentic_platform.core.tool.sample_tools import weather_report, handle_calculation\n",
    "\n",
    "# Define our agent prompt.\n",
    "class AgentPrompt(BasePrompt):\n",
    "    system_prompt: str = '''You are a helpful assistant.'''\n",
    "    user_prompt: str = '''{user_message}'''\n",
    "\n",
    "# Build out our prompt\n",
    "user_message: str = 'What is the weather in San Francisco?'\n",
    "prompt: BasePrompt = AgentPrompt()\n",
    "# Instantiate the agent\n",
    "\n",
    "tools: List[Callable] = [weather_report, handle_calculation]\n",
    "my_agent: LangChainAgent = LangChainAgent(base_prompt=prompt, tools=tools) \n",
    "\n",
    "# Create the agent request. Same as our other agent type in the tool calling lab.\n",
    "request: AgentRequest = AgentRequest(text=user_message)\n",
    "\n",
    "# Invoke the agent\n",
    "response: AgentResponse = my_agent.invoke(request)\n",
    "\n",
    "print(response.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"session_id\": \"3c181d9d-48eb-472b-9e34-db538fcb6bb1\",\n",
      "  \"user_id\": null,\n",
      "  \"agent_id\": null,\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"What is the weather in San Francisco?\"\n",
      "        }\n",
      "      ],\n",
      "      \"tool_calls\": [],\n",
      "      \"tool_results\": [],\n",
      "      \"timestamp\": 1747514636.711646\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"I'll help you check the weather in San Francisco right away.\"\n",
      "        }\n",
      "      ],\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"name\": \"weather_report\",\n",
      "          \"arguments\": {\n",
      "            \"location\": \"San Francisco\"\n",
      "          },\n",
      "          \"id\": \"tooluse_ZOgJSvcuRsy_cP-JDw_0gg\"\n",
      "        }\n",
      "      ],\n",
      "      \"tool_results\": [],\n",
      "      \"timestamp\": 1747514636.71167\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": null,\n",
      "      \"tool_calls\": [],\n",
      "      \"tool_results\": [\n",
      "        {\n",
      "          \"id\": \"tooluse_ZOgJSvcuRsy_cP-JDw_0gg\",\n",
      "          \"content\": [\n",
      "            {\n",
      "              \"type\": \"text\",\n",
      "              \"text\": \"The weather is sunny and 70 degrees.\"\n",
      "            }\n",
      "          ],\n",
      "          \"isError\": false\n",
      "        }\n",
      "      ],\n",
      "      \"timestamp\": 1747514636.711684\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"It looks like San Francisco is experiencing beautiful weather today! The current conditions are sunny with a temperature of 70 degrees, which sounds like a perfect day to be outdoors.\"\n",
      "        }\n",
      "      ],\n",
      "      \"tool_calls\": [],\n",
      "      \"tool_results\": [],\n",
      "      \"timestamp\": 1747514636.71169\n",
      "    }\n",
      "  ],\n",
      "  \"system_prompt\": null,\n",
      "  \"session_metadata\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Now lets look at our conversation.\n",
    "conversation: SessionContext = memory_client.get_or_create_conversation(response.session_id)\n",
    "# Use the pydantic model_dump_json\n",
    "print(conversation.model_dump_json(indent=2, serialize_as_any=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have interoperability!\n",
    "By adding some converters and wrapping LangChain/LangGraph in our own abstractions, we were able to \n",
    "1. Return the same agent response as our custom agent so we can reuse AgentRequest & AgentResponse types\n",
    "2. Have a universal memory implementation across different agents built with different frameworks\n",
    "3. Decoupled ourselves from relying too much on any framework, API provider, etc.. \n",
    "\n",
    "By owning our own types, we can begin to see how you can mix and match frameworks to get the best of both worlds while still maintaining control over your system. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic AI\n",
    "Pydantic AI is a newer framework. The main draw is type safety. you can create type safe graphs and build agents relatively quickly. It also works really well with pydantic models. \n",
    "\n",
    "In the examples with LangChain above, the react agent can't handle the nested pydantic objects of the calculator function and will usually error out unless you change your function definition. PydanticAI doesn't have that problem.\n",
    "\n",
    "It is fairly new (as of 4/20/2025) but is a framework worth watching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to use nest_asyncio which patches the asyncio to allow nested event loops which PydanticAI runs on.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Lets create a simple agent. We need to start aliasing the agent class to avoid conflict with the langchain agent.\n",
    "from pydantic_ai import Agent as PyAIAgent\n",
    "\n",
    "pyai_agent: PyAIAgent = PyAIAgent(\n",
    "    'bedrock:anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "    system_prompt='You are a helpful assistant.',\n",
    ")\n",
    "\n",
    "# Now lets add our existing tools to the agent. Notice how the tool object actually lives on the agent object itself. \n",
    "# Secondly, PydanticAI has two types of tools. tool() has access to the run context while tool_plain() does not.\n",
    "# We'll use the plain tool here since we don't need access to the run context.\n",
    "tools: List[Tool] = [pyai_agent.tool_plain(func)for func in [weather_report, handle_calculation]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So, 7 plus 7 equals 14.\n",
      "--------------------------------\n",
      "ModelRequest(parts=[SystemPromptPart(content='You are a helpful assistant.', timestamp=datetime.datetime(2025, 5, 17, 20, 43, 51, 246728, tzinfo=datetime.timezone.utc), dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='What is 7 plus 7?', timestamp=datetime.datetime(2025, 5, 17, 20, 43, 51, 246731, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request')\n",
      "ModelResponse(parts=[TextPart(content='To calculate 7 + 7, I will invoke the \"handle_calculation\" tool:', part_kind='text'), ToolCallPart(tool_name='handle_calculation', args={'operation': 'add', 'x': 7, 'y': 7}, tool_call_id='tooluse_S3vinbowRdO_48LvdyTabA', part_kind='tool-call')], model_name='anthropic.claude-3-sonnet-20240229-v1:0', timestamp=datetime.datetime(2025, 5, 17, 20, 43, 53, 90283, tzinfo=datetime.timezone.utc), kind='response')\n",
      "ModelRequest(parts=[ToolReturnPart(tool_name='handle_calculation', content=14.0, tool_call_id='tooluse_S3vinbowRdO_48LvdyTabA', timestamp=datetime.datetime(2025, 5, 17, 20, 43, 53, 92089, tzinfo=datetime.timezone.utc), part_kind='tool-return')], kind='request')\n",
      "ModelResponse(parts=[TextPart(content='So, 7 plus 7 equals 14.', part_kind='text')], model_name='anthropic.claude-3-sonnet-20240229-v1:0', timestamp=datetime.datetime(2025, 5, 17, 20, 43, 53, 771020, tzinfo=datetime.timezone.utc), kind='response')\n"
     ]
    }
   ],
   "source": [
    "result_sync = pyai_agent.run_sync('What is 7 plus 7?')\n",
    "print(result_sync.data)\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "for message in result_sync.all_messages():\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our Abstraction Layers\n",
    "Pydantic AI has a pretty clean design around agents. However, we still want to own our own types to make it interoperable with other parts of our system. Lets create our wrappers and converters like with did with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role='user' content=[TextContent(type='text', text='What is 7 plus 7?')] tool_calls=[] tool_results=[] timestamp=1747514633.7853\n",
      "role='assistant' content=[TextContent(type='text', text='To calculate 7 + 7, I will invoke the \"handle_calculation\" tool:')] tool_calls=[ToolCall(name='handle_calculation', arguments={'operation': 'add', 'x': 7, 'y': 7}, id='tooluse_S3vinbowRdO_48LvdyTabA')] tool_results=[] timestamp=1747514633.785328\n",
      "role='user' content=None tool_calls=[] tool_results=[ToolResult(id='tooluse_S3vinbowRdO_48LvdyTabA', content=[TextContent(type='text', text='14.0')], isError=False)] timestamp=1747514633.785348\n",
      "role='assistant' content=[TextContent(type='text', text='So, 7 plus 7 equals 14.')] tool_calls=[] tool_results=[] timestamp=1747514633.785355\n"
     ]
    }
   ],
   "source": [
    "# Like the langchain converter, this is undifferentiated code so we pushed it to the common folder.\n",
    "from agentic_platform.core.converter.pydanticai_converters import PydanticAIMessageConverter\n",
    "\n",
    "messages: List[Message] = PydanticAIMessageConverter.convert_messages(result_sync.all_messages())\n",
    "\n",
    "for message in messages:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewrite Our Agent in Pydantic\n",
    "Now we can rewrite our agent in Pydantic. We'll reuse the same memory client to show how we can store conversations across various frameworks / models without having to rewrite our code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent as PyAIAgent\n",
    "from pydantic_ai.models import ModelResponse\n",
    "\n",
    "class PydanticAIAgent:\n",
    "    \n",
    "    def __init__(self, tools: List[Callable], base_prompt: BasePrompt):\n",
    "        # This is the identifier for PydanticAI calling Bedrock.\n",
    "        model_id = f'bedrock:{base_prompt.model_id}'\n",
    "        self.agent: PyAIAgent = PyAIAgent(\n",
    "            model_id,\n",
    "            system_prompt=base_prompt.system_prompt,\n",
    "        )\n",
    "\n",
    "        # Add our tools to the agent.\n",
    "        [self.agent.tool_plain(func)for func in tools]\n",
    "\n",
    "    def invoke(self, request: AgentRequest) -> AgentResponse:\n",
    "        # Get or create conversation\n",
    "        conversation: SessionContext = memory_client.get_or_create_conversation(request.session_id)\n",
    "        # Convert to langchain messages\n",
    "        response: ModelResponse = self.agent.run_sync(request.text)\n",
    "        # Convert to our response format\n",
    "        messages: List[Message] = PydanticAIMessageConverter.convert_messages(response.all_messages())\n",
    "        # Add messages to conversation\n",
    "        conversation.add_messages(messages)\n",
    "        # Save the conversation\n",
    "        memory_client.upsert_conversation(conversation)\n",
    "        # Return the response\n",
    "        return AgentResponse(\n",
    "            session_id=conversation.session_id,\n",
    "            message=messages[-1].text\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like San Francisco is experiencing beautiful weather today! The current conditions are sunny with a temperature of 70 degrees, which sounds like a perfect day to be outdoors.\n"
     ]
    }
   ],
   "source": [
    "# Define our agent prompt.\n",
    "class AgentPrompt(BasePrompt):\n",
    "    system_prompt: str = '''You are a helpful assistant.'''\n",
    "    user_prompt: str = '''{user_message}'''\n",
    "\n",
    "# Build out our prompt\n",
    "user_message: str = 'What is the weather in San Francisco?'\n",
    "prompt: BasePrompt = AgentPrompt()\n",
    "# Instantiate the agent\n",
    "my_agent: PydanticAIAgent = PydanticAIAgent(base_prompt=prompt, tools=tools) \n",
    "\n",
    "# Create the agent request. Same as our other agent type in the tool calling lab.\n",
    "request: AgentRequest = AgentRequest(text=user_message)\n",
    "\n",
    "# Invoke the agent\n",
    "response: AgentResponse = my_agent.invoke(request)\n",
    "\n",
    "print(response.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"session_id\": \"3c181d9d-48eb-472b-9e34-db538fcb6bb1\",\n",
      "  \"user_id\": null,\n",
      "  \"agent_id\": null,\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"What is the weather in San Francisco?\"\n",
      "        }\n",
      "      ],\n",
      "      \"tool_calls\": [],\n",
      "      \"tool_results\": [],\n",
      "      \"timestamp\": 1747514636.711646\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"I'll help you check the weather in San Francisco right away.\"\n",
      "        }\n",
      "      ],\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"name\": \"weather_report\",\n",
      "          \"arguments\": {\n",
      "            \"location\": \"San Francisco\"\n",
      "          },\n",
      "          \"id\": \"tooluse_ZOgJSvcuRsy_cP-JDw_0gg\"\n",
      "        }\n",
      "      ],\n",
      "      \"tool_results\": [],\n",
      "      \"timestamp\": 1747514636.71167\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": null,\n",
      "      \"tool_calls\": [],\n",
      "      \"tool_results\": [\n",
      "        {\n",
      "          \"id\": \"tooluse_ZOgJSvcuRsy_cP-JDw_0gg\",\n",
      "          \"content\": [\n",
      "            {\n",
      "              \"type\": \"text\",\n",
      "              \"text\": \"The weather is sunny and 70 degrees.\"\n",
      "            }\n",
      "          ],\n",
      "          \"isError\": false\n",
      "        }\n",
      "      ],\n",
      "      \"timestamp\": 1747514636.711684\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"It looks like San Francisco is experiencing beautiful weather today! The current conditions are sunny with a temperature of 70 degrees, which sounds like a perfect day to be outdoors.\"\n",
      "        }\n",
      "      ],\n",
      "      \"tool_calls\": [],\n",
      "      \"tool_results\": [],\n",
      "      \"timestamp\": 1747514636.71169\n",
      "    }\n",
      "  ],\n",
      "  \"system_prompt\": null,\n",
      "  \"session_metadata\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Now lets look at our conversation.\n",
    "conversation: SessionContext = memory_client.get_or_create_conversation(response.session_id)\n",
    "# Use the pydantic model_dump_json\n",
    "print(conversation.model_dump_json(indent=2, serialize_as_any=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This concludes module 3 on autonomous agents. In this lab we:\n",
    "1. Explored 2 of the many agent frameworks available today\n",
    "2. Demonstrated how to make agent frameworks interoperable and create 2 way door decisions with proper abstraction in code. \n",
    "\n",
    "In the next module we'll be discussing some more advanced concepts of agents. Specifically multi-agent systems and model context protocol (MCP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
