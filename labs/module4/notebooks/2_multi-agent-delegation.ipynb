{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Systems: Calling Agents As Tools\n",
    "\n",
    "Welcome to this multi-agent lab! Here we'll explore the supervisor pattern, where one agent coordinates the work of other specialized agents.\n",
    "\n",
    "## Why Use Multiple Agents?\n",
    "Specialized agents perform better at specific tasks than a single agent trying to do everything. The supervisor agent delegates work to these specialists and manages the overall process.\n",
    "\n",
    "## What We'll Build\n",
    "In module 2, we used LangGraph so it seems fitting to pick a different framework (PydanticAI) to see how other frameworks work. We'll use PydanticAI to create a multi-agent system that can answer questions and debug an open search cluster. \n",
    "\n",
    "We'll create 3 agents:\n",
    "* A supervisor agent that manages all the other agents\n",
    "* A Researcher agent that has access to the internet and can research topics\n",
    "* A Writer agent that can take the information retrieved from the internet and create a report\n",
    "\n",
    "At the end of this module we should be on our way to creating a \"Deep Research\" Agentic system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our Researcher Agent\n",
    "Let's create a researcher agent that can create a research plan and get information from the internet to create a summary of the research. First lets double check that the instructions in 0_setup.ipynb were set up correctly and import our Search key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the .env file exist? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "# Check if you created the .env file before running this notebook.\n",
    "print('Does the .env file exist?', os.path.exists('.env'))\n",
    "# from dotenv import load_dotenv\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #fffbe6; border-left: 4px solid #faad14; padding: 15px; margin-bottom: 20px;\">\n",
    "<strong>⚠️ Warning</strong><br>\n",
    "If the command above doesn't say .env exists is true then you need to complete the 0_setup.ipynb notebook first to grab your tavily API key.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to use nest_asyncio which patches the asyncio to allow nested event loops which PydanticAI runs on.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build our Search Agent\n",
    "In this section we'll build an agent that can search the web and get results back (and annotations) to answer some tough questions. \n",
    "\n",
    "## A note on search\n",
    "We'll build the tool from scratch to demonstrate it's use but in practice there's a number of ways to DRY (Don't repeat yourself). Pydantic ships with a tavily tool you can just import. Tavily also has an MCP server available that you can use as well. The only reason you would write this yourself is if the default tool or MCP server doesn't output the results in the way you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Dict\n",
    "from agentic_platform.core.models.memory_models import ToolResult\n",
    "from agentic_platform.core.models.prompt_models import BasePrompt\n",
    "from tavily import TavilyClient\n",
    "#  We should start aliasing the agent class to avoid conflict with Agent objects from other frameworks. \n",
    "from pydantic_ai import Agent as PyAIAgent\n",
    "\n",
    "# Now lets create our research tools\n",
    "class WebSearch(BaseModel):\n",
    "    query: str\n",
    "\n",
    "def search_web(query: WebSearch) -> ToolResult:\n",
    "    '''Search the web to get back a list of results and content.'''\n",
    "    client: TavilyClient = TavilyClient(os.getenv(\"TAVILY_KEY\"))\n",
    "    response: Dict[str, any] = client.search(query=query.query)\n",
    "\n",
    "    return ToolResult(\n",
    "        content=[\n",
    "            {'type': 'json', 'content': response['results']}\n",
    "        ],\n",
    "        isError=False\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.search_web(query: __main__.WebSearch) -> agentic_platform.core.models.memory_models.ToolResult>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create prompt using our BasePrompt class. \n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a specialized Research Agent with web search capabilities. Your role is to:\n",
    "\n",
    "1. Analyze user queries and construct a question to query the internet with. \n",
    "2. Organize findings into comprehensive, well-sourced research briefs\n",
    "3. Return the research brief in a well structured format that a writer can use to write a report.\n",
    "4. Make sure to cite your sources with links in markdown format at the bottom of the research brief.\n",
    "\n",
    "Provide only the research based of your web search results in a format that a writer can use to write a report.\n",
    "Make sure to cite your sources with links in markdown format at the bottom of the research brief.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "Using the users research question as context, do all the research needed to answer the question.\n",
    "Remember, you are not writing the report. You are only providing the research needed to write the report.\n",
    "\"\"\"\n",
    "\n",
    "class ResearchPlanPrompt(BasePrompt):\n",
    "    system_prompt: str = SYSTEM_PROMPT\n",
    "    user_prompt: str = USER_PROMPT\n",
    "\n",
    "research_prompt: BasePrompt = ResearchPlanPrompt()\n",
    "\n",
    "research_agent: PyAIAgent = PyAIAgent(\n",
    "    'bedrock:us.anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    ")\n",
    "\n",
    "# Add our search tool to the agent.\n",
    "research_agent.tool_plain(search_web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the researcher agent individually\n",
    "research_question: str = \"What's different between how the US and the EU handle pasturization of milk?\"\n",
    "\n",
    "result = research_agent.run_sync(research_question)\n",
    "\n",
    "# Store this here to test our writer agent.\n",
    "research_brief = result.output\n",
    "\n",
    "print(result.output)\n",
    "print(result.usage())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our Writer Agent\n",
    "This agent will take in the research and be responsible for drafting the results of the response. It doesn't need any tools, but we do want it to write quickly so we'll use a smaller model to take the research and formulate a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt using our BasePrompt class. \n",
    "WRITER_SYSTEM_PROMPT = \"\"\"\n",
    "You are a specialized Writer Agent responsible for crafting polished, cohesive reports from research provided by the Research Agent. Your role is to:\n",
    "\n",
    "1. Transform the short research brief into a comprehensive report.\n",
    "2. Organize information logically with appropriate sections and flow\n",
    "3. Maintain a professional, authoritative tone appropriate for the subject matter\n",
    "4. Ensure clarity, conciseness, and readability for the target audience\n",
    "\n",
    "You will be provided with comprehensive research materials that include facts, figures, and sourced information. Your job is to synthesize this information without altering facts or adding unsupported claims.\n",
    "\n",
    "Please use complete sentenences and paragraphs. No bullet points. Break up the report into section with headers with the following format:\n",
    "Title:\n",
    "[Title of the report]\n",
    "\n",
    "Section 1:\n",
    "[Section 1 of the report]\n",
    "\n",
    "Conclusion:\n",
    "[Conclusion of the report]\n",
    "\"\"\"\n",
    "\n",
    "WRITER_USER_PROMPT = \"\"\"\n",
    "Using the research and users question provided as context, please write a comprehensive report addressing the following query.\n",
    "\"\"\"\n",
    "\n",
    "class WriterPrompt(BasePrompt):\n",
    "    system_prompt: str = WRITER_SYSTEM_PROMPT\n",
    "    user_prompt: str = WRITER_USER_PROMPT\n",
    "\n",
    "writer_prompt: BasePrompt = WriterPrompt()\n",
    "\n",
    "# Lets use a really fast model for the writer agent.\n",
    "writer_agent: PyAIAgent = PyAIAgent(\n",
    "    'bedrock:us.anthropic.claude-3-5-haiku-20241022-v1:0',\n",
    "    system_prompt=writer_prompt.system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the writer agent individually\n",
    "user_query: str = \"\"\"What's different between how the US and the EU handle pasturization of milk?\n",
    "\n",
    "Research Brief:\n",
    "{research_brief}\n",
    "\"\"\"\n",
    "\n",
    "user_query = user_query.format(research_brief=research_brief)\n",
    "results = writer_agent.run_sync(user_query)\n",
    "\n",
    "print(results.output)\n",
    "print(results.usage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Supervisor Agent\n",
    "Lastly, we need to create the supervisor agent. This agent is responsible for delegating work to it's workers. In Pydantic there's a couple ways to do this. For this experiment we will delegate using tools. The supervisor agent will have two tools that invoke the writer agent and researcher agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPERVISOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are a Supervisor Agent responsible for coordinating a multi-agent research system. Your role is to:\n",
    "\n",
    "1. Analyze user queries and coordinate the research and writing process\n",
    "2. Delegate specific tasks to the Research Agent and Writer Agent\n",
    "3. Ensure the final report fully addresses the user's query\n",
    "4. Return the Writer Agent's final report directly to the user without modification in <writer_output> tags.\n",
    "\n",
    "You must NOT analyze, summarize, or modify the Writer Agent's output. Your role is purely to coordinate the process and deliver the complete, unaltered report from the Writer Agent to the user.\n",
    "\n",
    "If the Writer Agent requests additional information, you should coordinate with the Research Agent to provide it, then return to the Writer Agent to complete the report.\n",
    "When the writer agent is done, copy the output and return it to the user.\n",
    "\n",
    "If the research isn't giving you exactly what you need, that's okay. Please don't call it multiple times.\n",
    "Remember, take the writers output and return it to the user in <writer_output> tags.\n",
    "\"\"\"\n",
    "\n",
    "SUPERVISOR_USER_PROMPT = \"\"\"\n",
    "Please help with the following query:\n",
    "{user_query}\n",
    "\n",
    "Your task is to:\n",
    "1. Coordinate with the Research Agent to gather necessary information\n",
    "2. Pass that research to the Writer Agent to create a final report\n",
    "3. Return the Writer Agent's complete report directly to the user without any additional commentary\n",
    "\n",
    "Do not add your own analysis or summarize the report - simply return the Writer Agent's complete output.\n",
    "\"\"\"\n",
    "\n",
    "class SupervisorPrompt(BasePrompt):\n",
    "    system_prompt: str = SUPERVISOR_SYSTEM_PROMPT\n",
    "    user_prompt: str = SUPERVISOR_USER_PROMPT\n",
    "\n",
    "\n",
    "# supervisor_prompt: BasePrompt = SupervisorPrompt()\n",
    "\n",
    "supervisor_agent: PyAIAgent = PyAIAgent(\n",
    "    'bedrock:us.anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "    system_prompt=SUPERVISOR_SYSTEM_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring everything together\n",
    "In Pydantic, you can pass the run context to tools. For our web search tool, it doesn't need the run context so we added the tool as tool_plain. For agents as tools, it needs the context so we'll set it up as a tool that takes in the run context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import RunContext\n",
    "\n",
    "@supervisor_agent.tool\n",
    "async def research_agent_tool(ctx: RunContext[None]) -> str:\n",
    "    '''Useful for researching a topic using the internet'''\n",
    "\n",
    "    # Useful to see what's going on. Please don't use print statements in production :) \n",
    "    print('entering research agent tool')\n",
    "    results = await research_agent.run(  \n",
    "        research_prompt.user_prompt,\n",
    "        usage=ctx.usage,  \n",
    "    )\n",
    "    return results.output \n",
    "\n",
    "@supervisor_agent.tool\n",
    "async def writer_agent_tool(ctx: RunContext[None], research_brief: str) -> str:\n",
    "    '''Useful for writing a report on a research topic provided the research is done.'''\n",
    "    \n",
    "    # Useful to see what's going on. Please don't use print statements in production :) \n",
    "    print('Entering the writer agent tool')\n",
    "\n",
    "    prompt = f'write a report on the following research brief: {research_brief}'\n",
    "    results = await writer_agent.run(\n",
    "        prompt,\n",
    "        usage=ctx.usage,  \n",
    "    )\n",
    "    return results.output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "research_question: str = \"What's different between how the US and the EU handle pasturization of milk?\"\n",
    "\n",
    "result = supervisor_agent.run_sync(research_question)\n",
    "print(result.output)\n",
    "print(result.usage())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "The multi-agent system is coordinating with a researcher and a writer to generate the final report for the user. However it's not the most efficient way of doing things. For one, the supervisor is verbatim copying the output of the writer agent verbatim. Secondly, there's no guardrails around how much the supervisor calls the researcher aside from asking it to not call it multiple times. \n",
    "\n",
    "This is a pretty naive implementation of this. In a production system, you'd probably want to either return directly from the writer agent or perform some more complex agent<>agent communication with things like reference passing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this lab we coordinated 3 agents together to answer questions and write reports using a SERPs API. In the next lab we'll coordinate agents using a Graph Structure. Graph orchestration is a much more practical and flexible approach to multi agent collaboration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
